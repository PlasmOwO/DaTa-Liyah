{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team name constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_tags_dico = {\n",
    "    \"SCL\" : [\"scl\",\"scald\"],\n",
    "    \"IWG\" : [\"iwg\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate Selenium web browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_options = webdriver.FirefoxOptions()\n",
    "driver_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=driver_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBlue_picks_bans(soup,name):\n",
    "    picks = soup.find(attrs={\"class\": \"roomPickColumn blue\"}).get_text(\"|\")\n",
    "    picks = picks.split(\"|\")\n",
    "    bans = [x['alt'] for x in soup.find(attrs={\"class\": \"roomBanRow blue\"}).find_all('img')]\n",
    "    return picks,bans, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRed_picks_bans(soup,name):\n",
    "    picks = soup.find(attrs={\"class\": \"roomPickColumn red\"}).get_text(\"|\")\n",
    "    picks = picks.split(\"|\")\n",
    "    bans = [x['alt'] for x in soup.find(attrs={\"class\": \"roomBanRow red\"}).find_all('img')]\n",
    "    return picks, bans, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_team_in_name(name,team_reference_dict, side) :\n",
    "\n",
    "    for tag, keywords in team_reference_dict.items():\n",
    "        for  word in keywords :\n",
    "            if word in name.lower()  :\n",
    "                return tag\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(name):\n",
    "\n",
    "    match = re.search(r'\\d', name)\n",
    "    if match :\n",
    "        digit_index = match.start()\n",
    "        return name[digit_index:]\n",
    "    return \"NaT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side_by_tag(soup,team_reference_dict):\n",
    "\n",
    "    blue_text = unicodedata.normalize(\"NFKD\",soup.find(attrs={\"class\" : \"roomReadyBackground roomReadyBackgroundblue\"}).previous_sibling.get_text())\n",
    "    red_text = unicodedata.normalize(\"NFKD\",soup.find(attrs={\"class\" : \"roomReadyBackground roomReadyBackgroundred\"}).previous_sibling.get_text())\n",
    "    \n",
    "    blue_team = detect_team_in_name(blue_text, team_reference_dict, \"Blue\")\n",
    "    red_team = detect_team_in_name(red_text,team_reference_dict, \"Red\")\n",
    "\n",
    "    if blue_team == \"SCL\" :\n",
    "        game_date = extract_date(blue_text)\n",
    "    elif red_team == \"SCL\" :\n",
    "        game_date = extract_date(red_text)\n",
    "    else :\n",
    "        game_date = \"NaT\"\n",
    "    return blue_team, red_team, game_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_draft(draft_url,team_reference_dict):\n",
    "\n",
    "    driver.get(draft_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    \n",
    "    teams_names = get_side_by_tag(soup,team_reference_dict)\n",
    "\n",
    "    blue = getBlue_picks_bans(soup,teams_names[0])\n",
    "    red = getRed_picks_bans(soup,teams_names[1])\n",
    "\n",
    "    bdd_draft_df = pd.DataFrame(columns=['link','draft_picks','draft_bans','team','side','date'])\n",
    "    bdd_draft_df = pd.concat([bdd_draft_df, pd.DataFrame([[draft_url,blue[0],blue[1],blue[2],'b',teams_names[2]]],columns=bdd_draft_df.columns)],axis=0)\n",
    "    \n",
    "    \n",
    "    return bdd_draft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraping_draft(\"https://draftlol.dawe.gg/ChTA4fbR\",team_tags_dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
